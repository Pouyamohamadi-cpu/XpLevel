print("Original text:", text)
print("Tokenized words:", words)
print("Filtered words:", filtered_words)
print("Word counts:", word_counts)